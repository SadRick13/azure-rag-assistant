services:
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./jupyter:/workspace
      - ./requirements.txt:/requirements.txt
    ports:
      - "8888:8888"
    command: >
      jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_origin='*'

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.11
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=NKKUvZLM0UGLBUsBZ7rm-3eQYxi98gkWPi2Fi6CAaKE=
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    volumes:
      - airflow_data:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/requirements.txt:/requirements.txt
    command: >
      bash -c "
        pip install -r /requirements.txt &&
        airflow db init &&
        airflow webserver
      "
    ports:
      - "8080:8080"
    env_file:
      - .env

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.11
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=somefernetkeyhere
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    volumes:
      - airflow_data:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/requirements.txt:/requirements.txt
    command: >
      bash -c "
        pip install -r /requirements.txt &&
        airflow scheduler
      "
    env_file:
      - .env

volumes:
  airflow_data:
